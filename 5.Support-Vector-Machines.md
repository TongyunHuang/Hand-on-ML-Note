## 1.Linear SVM Classification
You can think of an SVM classifier as fitting the widest possible stree between the classes. This is called large margin classification

### 1.1 Soft Margin Classification
Hard Margin Classification: strictly impose that all instances must be off the street
  - CONS: (1) Only works if the data is linearly separable (2) sensitive to outliers

## 2.Nonlinear SVM Classification 
### 2.1 Polynomial Kernel
SVMs provides "kernel tricks": makes it possible to get the same result as if you had added many polynomial features, even with very high-degree polynomials, without actually haveing to add them

### 2.2 Similarity Features
### 2.3 Gaussian RBF Kernel
### 2.4 Computational Complexity
$O(m^2 \times n)$

Only suitable for small or medium size training set

## 3.SVM Regression
## 4.Under the Hood